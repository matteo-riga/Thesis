{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9802504-1823-4b44-becd-9103769793ed",
   "metadata": {},
   "source": [
    "# Analysis on secure logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53b279e-e4ee-4818-9fc8-114099f0e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbd8efe-3368-4b32-84fb-e0a1c122d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "sys.path.append('../src/')\n",
    "sys.path.append('../spell/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec0691-73d2-4c4c-b66f-9dfcf857dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 14:49:55.632626: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-06 14:49:55.633237: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-06 14:49:55.636703: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-06 14:49:55.684153: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import Reader\n",
    "import ParamsExtractor3\n",
    "import DataPreprocessor\n",
    "import DeepLearningAnomalyDetection2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e95807-cfea-4725-9aa7-9ebd79d7e94c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e266b1-5572-4af4-bee5-c5880d87f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_types = ['laurel']\n",
    "dates = ['20240418', '20240420', '20240429']\n",
    "login_node_numbers = ['01', '02', '03', '10']\n",
    "\n",
    "# Generate the list of file paths\n",
    "file_paths = [f'/../../../temp_logs/{date}/login{num}.{logtype}.log' for date in dates for num in login_node_numbers for logtype in log_types]\n",
    "\n",
    "# Filter the list to include only existing files\n",
    "existing_file_paths = [path for path in file_paths if os.path.exists(path)]\n",
    "print(existing_file_paths)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file_path in existing_file_paths:\n",
    "    r = Reader.Reader(file_path)\n",
    "    df = r.read_file(file_path)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb1dc7-2d37-45d4-8f32-c45679635ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b3071-1dda-49d0-bbfa-7e7368f67d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after = []\n",
    "\n",
    "for i, df in enumerate(df_list):\n",
    "    p = ParamsExtractor3.ParamsExtractor(df)\n",
    "    df = p.convert_params(df)\n",
    "    new_df = p.get_params()\n",
    "    df_after.append(new_df)\n",
    "    df_list[i] = pd.concat([df_list[i], new_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1dbb0-17f4-456e-8522-de644baf4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcebc85-4d65-4de4-8445-c9644fa36df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].iloc[0]['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc8c57b-7911-4f18-b9f5-4c2440f9b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(df_list):\n",
    "    d = DataPreprocessor.DataPreprocessor(df)\n",
    "    enc = d.drop_and_hash_encode()\n",
    "    df_list[i] = enc\n",
    "\n",
    "print(df_list[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480c325-8793-469e-912d-7e41bfdb8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f3518-c530-4536-ab4c-ee91177de6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_list[0]\n",
    "\n",
    "for i in range(1,len(df_list)):\n",
    "    normal_dataset = np.vstack([normal_dataset, df_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30bf1f6-b70e-4e95-ad32-a537a9270f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854c17ff-1bd6-4034-b62e-bdc5d41f7f23",
   "metadata": {},
   "source": [
    "## Anomalies' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7992594-3016-4216-a190-dd8e162fc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_types = ['laurel']\n",
    "\n",
    "# Generate the list of file paths\n",
    "file_paths = [f'../data/linpeas_logs_1/{logtype}_logs.log' for logtype in log_types]\n",
    "\n",
    "# Filter the list to include only existing files\n",
    "existing_file_paths = [path for path in file_paths if os.path.exists(path)]\n",
    "\n",
    "an_df_list = []\n",
    "\n",
    "for file_path in existing_file_paths:\n",
    "    r = Reader.Reader(file_path)\n",
    "    df = r.read_file_2(file_path)\n",
    "    an_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0bba3-051b-4dba-8f9f-65cea6f63d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b176f7-c733-4da5-b901-975dae3ee361",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_df_after = []\n",
    "\n",
    "for i, df in enumerate(an_df_list):\n",
    "    p = ParamsExtractor3.ParamsExtractor(df)\n",
    "    df = p.convert_params(df)\n",
    "    new_df = p.get_params()\n",
    "    an_df_after.append(new_df)\n",
    "    an_df_list[i] = pd.concat([an_df_list[i], new_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d5c47-d290-4191-878f-6d01b7ce4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b973e5-2b81-4644-a9e7-66f0beb8b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(an_df_list):\n",
    "    d = DataPreprocessor.DataPreprocessor(df)\n",
    "    enc = d.drop_and_hash_encode()\n",
    "    an_df_list[i] = enc\n",
    "\n",
    "print(an_df_list[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980bc78-f2b7-4208-a783-a1009b99037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we test secure\n",
    "# we take the lines from the 230th (detected pwd bruteforcing)\n",
    "anomalous_dataset = an_df_list[0][230:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c1dfc-0c30-41b1-ad5c-038405ea4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c88118-b8f0-4cbf-8f1a-c5a31ce42e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f2105-f32b-44fc-8573-e0550aed9319",
   "metadata": {},
   "source": [
    "## Library implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3f29b-ee28-4bae-a51f-8f225e45d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset_df = pd.DataFrame(normal_dataset, columns=anomalous_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae37111-9a50-4b81-ae8f-9f06ecae048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset_reduced = normal_dataset_df[['severity_scores', 'timedelta', 'port', 'log key', 'log key spell',\n",
    "       'n_dang', 'n_dang_no_cron', 'fp_length']]\n",
    "anomalous_dataset_reduced = anomalous_dataset[['severity_scores', 'timedelta', 'port', 'log key', 'log key spell',\n",
    "       'n_dang', 'n_dang_no_cron', 'fp_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15723da0-d03c-48ea-abc2-3efa6b5f5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_an_det = DeepLearningAnomalyDetection2.DeepLearningAnomalyDetection()\n",
    "true_anomalies, reconstructed_anomalies = d_an_det.train_test_model(normal_dataset_df, anomalous_dataset, 'autoencoder', plots=[0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69652f-3966-4c54-a4a6-65e280ee832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_an_det = DeepLearningAnomalyDetection2.DeepLearningAnomalyDetection()\n",
    "true_anomalies_vae, reconstructed_anomalies_vae = d_an_det.train_test_model(normal_dataset_df, anomalous_dataset, 'vae', plots=[0,0,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d5f6c4-9310-45c5-8456-b885ebc6e3be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf125b-0b38-4d4b-8667-0ef17b5ac37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_an_det.ensemble_method(normal_dataset_df, anomalous_dataset, plots=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f718f-33b8-4543-b6f2-c52f0469c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example predictions from two models (replace with your actual predictions)\n",
    "predictions_model1 = reconstructed_anomalies\n",
    "predictions_model2 = reconstructed_anomalies_vae\n",
    "\n",
    "# Combine predictions using logical OR (voting scheme)\n",
    "combined_predictions = np.logical_and(predictions_model1, predictions_model2).astype(int)\n",
    "\n",
    "# Example thresholding (adjust as needed)\n",
    "threshold = 0.5  # Simple majority voting\n",
    "\n",
    "# Convert to final anomaly predictions based on threshold\n",
    "final_predictions = (combined_predictions >= threshold).astype(int)\n",
    "\n",
    "# Print or use the final predictions\n",
    "print(\"Combined Predictions:\", combined_predictions)\n",
    "print(\"Final Anomaly Predictions:\", final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27818862-17f9-4d42-bba1-1e5c9c4e7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ae0e5-e2f9-4040-8510-e2af8d3452fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example ground truth and predictions (replace with your actual data)\n",
    "ground_truth = true_anomalies\n",
    "predictions = final_predictions\n",
    "            \n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(ground_truth, predictions)\n",
    "            \n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                        xticklabels=['Normal', 'Anomaly'], \n",
    "                        yticklabels=['Normal', 'Anomaly'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
