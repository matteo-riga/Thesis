{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parser_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Extraction Leveraging Domain Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_dict = {\n",
    "    \"emerg\": 0,\n",
    "    \"alert\": 1,\n",
    "    \"crit\": 2,\n",
    "    \"error\": 3,\n",
    "    \"warn\": 4,\n",
    "    \"notice\": 5,\n",
    "    \"info\": 6,\n",
    "    \"debug\": 7\n",
    "}\n",
    "\n",
    "facility_dict = {\n",
    "    \"kern\": 0,\n",
    "    \"user\": 1,\n",
    "    \"mail\": 2,\n",
    "    \"system\": 3,\n",
    "    \"auth\": 4,\n",
    "    \"<syslog?>\": 5,\n",
    "    \"<line printer?>\": 6,\n",
    "    \"news\": 7,\n",
    "    \"uucp\": 8,\n",
    "    \"clock\": 9,\n",
    "    \"authpriv\": 10,\n",
    "    \"ftp\": 11,\n",
    "    \"ntp\": 12,\n",
    "    \"<log audit?>\": 13,\n",
    "    \"<log alert?>\": 14,\n",
    "    \"local0\": 16,\n",
    "    \"local1\": 17,\n",
    "    \"local2\": 18,\n",
    "    \"local3\": 19,\n",
    "    \"local4\": 20,\n",
    "    \"local5\": 21,\n",
    "    \"local6\": 22,\n",
    "    \"local7\": 23,\n",
    "    \"cron\":16, # ipotizzando che cron stia usando local0\n",
    "    \"daemon\":17 # ipotizzando che laurel stia usando local0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_logs_cron.txt', 'sample_logs_laurel.txt', 'sample_logs_maillog.txt', 'sample_logs_messages.txt', 'sample_logs_secure.txt', 'sample_logs_user.txt']\n"
     ]
    }
   ],
   "source": [
    "# general log preprocessing analysis for each type of log\n",
    "log_types = ['cron', 'laurel', 'maillog', 'messages', 'secure', 'user']\n",
    "file_paths = ['sample_logs_' + logtype + '.txt' for logtype in log_types]\n",
    "\n",
    "print(file_paths)\n",
    "\n",
    "# Severity normal level (established arbitrarily)\n",
    "normal_level = \"info\"\n",
    "normal_level_numerical = severity_dict[normal_level]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = parser_1.parse_file_to_df(file_path)\n",
    "    # Create severity and facility ID numbers for each dataframe\n",
    "    df['severity_numbers'] = [severity_dict[elem] for elem in df['severity']]\n",
    "    df['facility_numbers'] = [facility_dict[elem] for elem in df['facility']]\n",
    "    # Create severity scores\n",
    "    df['severity_scores'] = [np.exp(normal_level_numerical-elem) for elem in df['severity_numbers']]\n",
    "    # Append time deltas\n",
    "    timedeltas = []\n",
    "    for i, date_str in enumerate(df['time']):\n",
    "        if i == 0:\n",
    "            timedeltas.append(0)\n",
    "        else:\n",
    "            date = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S %z')\n",
    "            date_prev = datetime.strptime(df['time'][i-1], '%Y-%m-%d %H:%M:%S %z')\n",
    "            timedelta = date - date_prev\n",
    "            timedeltas.append(timedelta.total_seconds())\n",
    "\n",
    "    df['timedelta'] = timedeltas\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for each log report type we need to call the appropriate preprocessing function\n",
    "# Dataframes are contained in df_list\n",
    "# Names of log types are containes in log_types\n",
    "\n",
    "def get_function(log_type):\n",
    "    switcher = {\n",
    "        \"cron\": preprocess.preprocess_message_cron,\n",
    "        \"laurel\": preprocess.preprocess_message_laurel,\n",
    "        \"maillog\": preprocess.preprocess_message_maillog,\n",
    "        \"messages\": preprocess.preprocess_message_messages,\n",
    "        \"secure\": preprocess.preprocess_message_secure,\n",
    "        \"user\": preprocess.preprocess_message_user\n",
    "    }\n",
    "\n",
    "    return switcher.get(log_type, \"Invalid Log Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      host  ident    pid                                            message  \\\n",
      "0  login01  CROND  50050   /bin/timeout 239m /cineca/asdata/bin/cindata....   \n",
      "1  login01  CROND  50055  source /g100_work/CMCC_medfs_0/download/set_en...   \n",
      "2  login01  CROND  50056  sh /g100_work/CMCC_medfs_0/download/dasDwlRawS...   \n",
      "3  login01  CROND  50057  sh /g100_work/CMCC_medfs_0/download/dasDwlRawS...   \n",
      "4  login01  CROND  50058  source /g100_work/CMCC_medfs_0/download/set_en...   \n",
      "\n",
      "  severity facility                       time  severity_numbers  \\\n",
      "0     info     cron  2024-03-27 23:15:01 +0100                 6   \n",
      "1     info     cron  2024-03-27 23:15:01 +0100                 6   \n",
      "2     info     cron  2024-03-27 23:15:01 +0100                 6   \n",
      "3     info     cron  2024-03-27 23:15:01 +0100                 6   \n",
      "4     info     cron  2024-03-27 23:15:01 +0100                 6   \n",
      "\n",
      "   facility_numbers  severity_scores  timedelta      user  \\\n",
      "0                16              1.0        0.0  acctdata   \n",
      "1                16              1.0        0.0  a07cmc01   \n",
      "2                16              1.0        0.0  a07cmc01   \n",
      "3                16              1.0        0.0  a07cmc01   \n",
      "4                16              1.0        0.0  a07cmc01   \n",
      "\n",
      "   common_file_paths_length  \n",
      "0                         1  \n",
      "1                         2  \n",
      "2                         3  \n",
      "3                         3  \n",
      "4                         2  \n",
      "{'pam_unix(sshd:session): session closed for *': 0, '* from * * ssh2: RSA SHA256:o5NSd6T8LbVSUcC9NP+0kCLlFY2n6Coli0UI8aWqY5g': 1, 'pam_unix(sshd:session): session opened for * by (uid=0)': 2, 'ganglia : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/cinecalocal/scripts/cat_llite.sh': 3, 'pam_unix(sudo:session): session opened for * by (uid=0)': 4, 'pam_unix(sudo:session): session closed for *': 5}\n",
      "{'Process * (node) of user * dumped core.': 0}\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(df_list):\n",
    "    func = get_function(log_types[i])\n",
    "    df = func(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "cron\n",
      "Index(['host', 'ident', 'pid', 'message', 'severity', 'facility', 'time',\n",
      "       'severity_numbers', 'facility_numbers', 'severity_scores', 'timedelta',\n",
      "       'user', 'common_file_paths_length'],\n",
      "      dtype='object')\n",
      "==============\n",
      "laurel\n",
      "Index(['host', 'ident', 'message', 'severity', 'facility', 'time',\n",
      "       'severity_numbers', 'facility_numbers', 'severity_scores', 'timedelta',\n",
      "       'suid'],\n",
      "      dtype='object')\n",
      "==============\n",
      "maillog\n",
      "Index(['host', 'ident', 'pid', 'message', 'severity', 'facility', 'time',\n",
      "       'severity_numbers', 'facility_numbers', 'severity_scores', 'timedelta'],\n",
      "      dtype='object')\n",
      "==============\n",
      "messages\n",
      "Index(['host', 'ident', 'pid', 'message', 'severity', 'facility', 'time',\n",
      "       'severity_numbers', 'facility_numbers', 'severity_scores', 'timedelta'],\n",
      "      dtype='object')\n",
      "==============\n",
      "secure\n",
      "Index(['host', 'ident', 'pid', 'message', 'severity', 'facility', 'time',\n",
      "       'severity_numbers', 'facility_numbers', 'severity_scores', 'timedelta'],\n",
      "      dtype='object')\n",
      "==============\n",
      "user\n",
      "Index(['host', 'ident', 'pid', 'message', 'severity', 'facility', 'time',\n",
      "       'severity_numbers', 'facility_numbers', 'severity_scores', 'timedelta',\n",
      "       'process', 'user_ns', 'keys'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(df_list):\n",
    "    print('==============')\n",
    "    print(log_types[i])\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: suid, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[1]['suid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['message', 'severity', 'facility', 'time' ,'severity_numbers']\n",
    "columns_to_encode =['host', 'ident', 'pid', 'facility_numbers', 'user']\n",
    "\n",
    "encoded_df_list = []\n",
    "\n",
    "for i,df in enumerate(df_list):\n",
    "    #print('================')\n",
    "    for col in columns_to_drop:\n",
    "        try:\n",
    "            #print(f'removed {col} from df {i}')\n",
    "            df = df.drop(columns=col)\n",
    "            #print(f'shape {df.shape}')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for col in columns_to_encode:\n",
    "        try:\n",
    "            df = pd.get_dummies(df, columns=[col])\n",
    "            #print(f'encoded {col} from df {i}')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #print(f'shape {df.shape}')\n",
    "        \n",
    "    encoded_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity_scores</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>suid</th>\n",
       "      <th>host_login01</th>\n",
       "      <th>ident_laurel</th>\n",
       "      <th>facility_numbers_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   severity_scores  timedelta  suid  host_login01  ident_laurel  \\\n",
       "0              1.0        0.0     0             1             1   \n",
       "1              1.0        0.0     0             1             1   \n",
       "2              1.0        0.0     0             1             1   \n",
       "3              1.0        0.0     0             1             1   \n",
       "4              1.0        0.0     0             1             1   \n",
       "5              1.0        0.0     0             1             1   \n",
       "6              1.0        0.0     0             1             1   \n",
       "7              1.0        0.0     0             1             1   \n",
       "8              1.0        0.0     0             1             1   \n",
       "9              1.0        0.0     0             1             1   \n",
       "\n",
       "   facility_numbers_22  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "5                    1  \n",
       "6                    1  \n",
       "7                    1  \n",
       "8                    1  \n",
       "9                    1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['host', 'ident', 'pid', 'message', 'severity', 'facility', 'time',\n",
       "       'severity_numbers', 'facility_numbers', 'severity_scores', 'timedelta',\n",
       "       'user', 'common_file_paths_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0].columns\n",
    "#cat_cols.append(['host', 'ident', 'facility_numbers', 'severity_scores', 'suid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['host', 'ident', 'pid', 'message', 'severity', 'facility', 'time',\n",
       "       'severity_numbers', 'facility_numbers', 'severity_scores', 'timedelta',\n",
       "       'user', 'common_file_paths_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['common_file_paths'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m target_df \u001b[38;5;241m=\u001b[39m df_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m target_df \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseverity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacility\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseverity_numbers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcommon_file_paths\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m target_df\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['common_file_paths'] not found in axis\""
     ]
    }
   ],
   "source": [
    "target_df = df_list[0]\n",
    "target_df = target_df.drop(columns=['message', 'severity', 'facility', 'time' ,'severity_numbers', 'common_file_paths'])\n",
    "target_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['host', 'ident', 'pid', 'facility_numbers', 'user']\n",
    "target_df = pd.get_dummies(target_df, columns=columns_to_encode)\n",
    "print(target_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame (replace this with your actual DataFrame)\n",
    "data = target_df\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(data)\n",
    "\n",
    "# Transform the data to principal componentsa\n",
    "transformed_data = pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(transformed_data[:, 0], transformed_data[:, 1], transformed_data[:, 2], s=50)\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "\n",
    "plt.title('Scatter Plot along the first 3 PCs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative explained variance\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Perform t-SNE decomposition\n",
    "tsne = TSNE(n_components=3)  # Set the number of components to 3 for 3D visualization\n",
    "tsne_components = tsne.fit_transform(data)\n",
    "\n",
    "# Plotting scatter plot along the t-SNE components\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(tsne_components[:, 0], tsne_components[:, 1], tsne_components[:, 2], s=50)\n",
    "\n",
    "ax.set_xlabel('t-SNE Component 1')\n",
    "ax.set_ylabel('t-SNE Component 2')\n",
    "ax.set_zlabel('t-SNE Component 3')\n",
    "\n",
    "plt.title('Scatter Plot along t-SNE Components')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "# Perform UMAP decomposition\n",
    "umap_emb = umap.UMAP(n_components=3)  # Set the number of components to 3 for 3D visualization\n",
    "umap_components = umap_emb.fit_transform(data)\n",
    "\n",
    "# Plotting scatter plot along the UMAP components\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(umap_components[:, 0], umap_components[:, 1], umap_components[:, 2], s=50)\n",
    "\n",
    "ax.set_xlabel('UMAP Component 1')\n",
    "ax.set_ylabel('UMAP Component 2')\n",
    "ax.set_zlabel('UMAP Component 3')\n",
    "\n",
    "plt.title('Scatter Plot along UMAP Components')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Perform DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.7, min_samples=3)\n",
    "labels = dbscan.fit_predict(umap_components)\n",
    "\n",
    "# Plotting scatter plot along the UMAP components with different colors for clusters\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Visualizing each cluster with a different color\n",
    "unique_labels = np.unique(labels)\n",
    "colors = plt.cm.jet(np.linspace(0, 1, len(unique_labels)))\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    cluster_data = umap_components[labels == label]\n",
    "    ax.scatter(cluster_data[:, 0], cluster_data[:, 1], cluster_data[:, 2], c=[color], label=f'Cluster {label}')\n",
    "\n",
    "ax.set_xlabel('UMAP Component 1')\n",
    "ax.set_ylabel('UMAP Component 2')\n",
    "ax.set_zlabel('UMAP Component 3')\n",
    "\n",
    "plt.title('DBSCAN Clustering on UMAP Components')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df['labels'] = labels\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
